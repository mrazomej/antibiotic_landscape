{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) 2024 Manuel Razo. This work is licensed under a [Creative Commons\n",
    "Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/).\n",
    "All code contained herein is licensed under an [MIT\n",
    "license](https://opensource.org/licenses/MIT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project package\n",
    "import Antibiotic\n",
    "import Antibiotic.mh as mh\n",
    "\n",
    "# Import ML libraries\n",
    "import CUDA\n",
    "import cuDNN\n",
    "import AutoEncoderToolkit as AET\n",
    "import Flux\n",
    "\n",
    "# Import libraries to handle data\n",
    "import Glob\n",
    "import DimensionalData as DD\n",
    "import DataFrames as DF\n",
    "import JLD2\n",
    "\n",
    "# Import basic math libraries\n",
    "import StatsBase\n",
    "import LinearAlgebra\n",
    "import Random\n",
    "import Distributions\n",
    "import Distances\n",
    "\n",
    "# Load CairoMakie for plotting\n",
    "import Makie\n",
    "using CairoMakie\n",
    "import PairPlots\n",
    "import ColorSchemes\n",
    "\n",
    "# Activate backend\n",
    "CairoMakie.activate!()\n",
    "\n",
    "# Set PBoC Plotting style\n",
    "Antibiotic.viz.theme_makie!()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Latent to Phenotypic Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will explore the problem of mapping the learned latent\n",
    "space representation into the original phenotypic space. Our Metropolis-Hastings\n",
    "evolutionary dynamics assign coordinates in phenotypic space for particular\n",
    "random walkers that represent an evolving population. These walkers undergo\n",
    "adaptive dynamics on a specific fitness landscape and a genetic density\n",
    "landscape, trying to increase their overall fitness. Then, we sample multiple\n",
    "fitness landscapes, computing the corresponding fitness for each phenotypic\n",
    "coordinate the walkers visited. Finally, given only these fitness values, we\n",
    "train an `RHVAE` model to map the high-dimensional fitness profile into a\n",
    "low-dimensional latent space.\n",
    "\n",
    "We can think of this process as a form of _non-linear triangulation_, where\n",
    "we use the fitness information to backtrack the relative positions of each\n",
    "walker in the phenotypic space. This is a form of _inverse_ problem, where we\n",
    "are trying to infer the _causes_ (i.e. the phenotypic coordinates) of the\n",
    "observed _effects_ (i.e. the fitness values).\n",
    "\n",
    "An immediate consequence of this interpretation of the learned latent space is\n",
    "that there must exist a _bijective_ mapping between the phenotypic space and the\n",
    "latent space. This is a very strong requirement, and it is something that we\n",
    "should be able to test empirically. What this means is that there must exist a\n",
    "function $\\underline{g}$ such that $\\underline{g}(\\underline{z}) =\n",
    "\\underline{x}$, where $\\underline{z} \\in \\mathbb{R}^d$ is a point in the latent\n",
    "space and $\\underline{x} \\in \\mathbb{R}^n$ is a point in the phenotypic space.\n",
    "Of course, this function is not known, but we can try to infer it from the data\n",
    "using a simple neural network architecture. This is the object of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading simulated dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading the simulated dynamics in phenotypic space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate current directory\n",
    "path_dir = \"$(git_root())/code/processing/metropolis-hastings_sim/v02\"\n",
    "\n",
    "# Find the path perfix where input data is stored\n",
    "out_prefix = replace(\n",
    "    match(r\"processing/(.*)\", path_dir).match,\n",
    "    \"processing\" => \"\",\n",
    ")\n",
    "\n",
    "# Define simulation directory\n",
    "sim_dir = \"$(git_root())/output$(out_prefix)/sim_evo\"\n",
    "# Define model directory\n",
    "vae_dir = \"$(git_root())/output$(out_prefix)/vae\"\n",
    "# Define output directory\n",
    "state_dir = \"$(vae_dir)/model_state\"\n",
    "\n",
    "# Define the subsampling interval\n",
    "n_sub = 10\n",
    "\n",
    "# Load fitnotype profiles\n",
    "fitnotype_profiles = JLD2.load(\"$(sim_dir)/sim_evo.jld2\")[\"fitnotype_profiles\"]\n",
    "\n",
    "# Extract initial and final time points\n",
    "t_init, t_final = collect(DD.dims(fitnotype_profiles, :time)[[1, end]])\n",
    "# Subsample time series\n",
    "fitnotype_profiles = fitnotype_profiles[time=DD.At(t_init:n_sub:t_final)]\n",
    "\n",
    "# Define number of environments\n",
    "n_env = length(DD.dims(fitnotype_profiles, :landscape))\n",
    "\n",
    "# Extract fitness data bringing the fitness dimension to the first dimension\n",
    "fit_data = permutedims(fitnotype_profiles.fitness, (5, 1, 2, 3, 4, 6))\n",
    "# Reshape the array to a Matrix\n",
    "fit_data = reshape(fit_data.data, size(fit_data.data, 1), :)\n",
    "\n",
    "# Log-transform fitness data\n",
    "fit_mat = log.(fit_data)\n",
    "\n",
    "# Fit model to standardize data to mean zero and standard deviation 1 on each\n",
    "# environment \n",
    "dt = StatsBase.fit(StatsBase.ZScoreTransform, fit_mat, dims=2)\n",
    "\n",
    "# Standardize the data to have mean 0 and standard deviation 1\n",
    "log_fitnotype_std = DD.DimArray(\n",
    "    mapslices(slice -> StatsBase.transform(dt, slice),\n",
    "        log.(fitnotype_profiles.fitness.data),\n",
    "        dims=[5]),\n",
    "    fitnotype_profiles.fitness.dims,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fitnotype_std = DD.mapslices(\n",
    "    slice -> StatsBase.transform(dt, slice),\n",
    "    log.(fitnotype_profiles.fitness),\n",
    "    dims=:landscape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the phenotype data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig = Figure(size=(350, 350))\n",
    "\n",
    "# Add axis\n",
    "ax = Axis(\n",
    "    fig[1, 1],\n",
    "    aspect=AxisAspect(1),\n",
    "    xlabel=\"phenotype 1\",\n",
    "    ylabel=\"phenotype 2\",\n",
    ")\n",
    "\n",
    "# Plot scatter\n",
    "mapslices(\n",
    "    slice -> scatter!(\n",
    "        ax,\n",
    "        Point2f.(eachcol(slice)),\n",
    "        markersize=5,\n",
    "        color=ColorSchemes.seaborn_colorblind[1],\n",
    "    ),\n",
    "    fitnotype_profiles.phenotype[landscape=DD.At(1)].data,\n",
    "    dims=[1],\n",
    ")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading `RHVAE` model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data in hand, we can now load the `RHVAE` model that we trained on\n",
    "the fitness profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function hyper-parameters\n",
    "ϵ = Float32(1E-3) # Leapfrog step size\n",
    "K = 10 # Number of leapfrog steps\n",
    "βₒ = 0.3f0 # Initial temperature for tempering\n",
    "\n",
    "# Define RHVAE hyper-parameters in a dictionary\n",
    "rhvae_kwargs = (K=K, ϵ=ϵ, βₒ=βₒ,)\n",
    "\n",
    "# Find model file\n",
    "model_file = first(Glob.glob(\"$(vae_dir)/model*.jld2\"[2:end], \"/\"))\n",
    "# List epoch parameters\n",
    "model_states = sort(Glob.glob(\"$(state_dir)/*.jld2\"[2:end], \"/\"))\n",
    "# Load model\n",
    "rhvae = JLD2.load(model_file)[\"model\"]\n",
    "# Load latest model state\n",
    "Flux.loadmodel!(rhvae, JLD2.load(model_states[end])[\"model_state\"])\n",
    "# Update metric parameters\n",
    "AET.RHVAEs.update_metric!(rhvae)\n",
    "\n",
    "typeof(rhvae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's map the fitness profiles into the `RHVAE` latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define latent space dimensions\n",
    "latent = DD.Dim{:latent}([:latent1, :latent2])\n",
    "\n",
    "# Map data to latent space\n",
    "dd_latent = DD.DimArray(\n",
    "    dropdims(\n",
    "        mapslices(slice -> rhvae.vae.encoder(slice).μ,\n",
    "            log_fitnotype_std.data,\n",
    "            dims=[5]);\n",
    "        dims=1\n",
    "    ),\n",
    "    (log_fitnotype_std.dims[2:4]..., latent, log_fitnotype_std.dims[6]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the latent space coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig = Figure(size=(350, 350))\n",
    "\n",
    "# Add axis\n",
    "ax = Axis(\n",
    "    fig[1, 1],\n",
    "    aspect=AxisAspect(1),\n",
    "    xlabel=\"latent dimension 1\",\n",
    "    ylabel=\"latent dimension 2\",\n",
    ")\n",
    "\n",
    "# Plot scatter\n",
    "mapslices(\n",
    "    slice -> scatter!(\n",
    "        ax,\n",
    "        Point2f.(eachcol(slice)),\n",
    "        markersize=5,\n",
    "        color=ColorSchemes.seaborn_colorblind[1],\n",
    "    ),\n",
    "    dd_latent.data,\n",
    "    dims=[4],\n",
    ")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the comparison between the phenotype and latent space coordinates even\n",
    "more obvious, let's plot both coordinates next to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig = Figure(size=(600, 300))\n",
    "\n",
    "# Add axis for phenotype coordinates\n",
    "ax_pheno = Axis(\n",
    "    fig[1, 1],\n",
    "    aspect=AxisAspect(1),\n",
    "    xlabel=\"phenotype 1\",\n",
    "    ylabel=\"phenotype 2\",\n",
    "    title=\"Phenotype space\",\n",
    ")\n",
    "\n",
    "# Add axis for latent coordinates\n",
    "ax_latent = Axis(\n",
    "    fig[1, 2],\n",
    "    aspect=AxisAspect(1),\n",
    "    xlabel=\"latent dimension 1\",\n",
    "    ylabel=\"latent dimension 2\",\n",
    "    title=\"Latent space\",\n",
    ")\n",
    "\n",
    "# Plot scatter for phenotype coordinates\n",
    "mapslices(\n",
    "    slice -> scatter!(\n",
    "        ax_pheno,\n",
    "        Point2f.(eachcol(slice)),\n",
    "        markersize=5,\n",
    "        color=ColorSchemes.seaborn_colorblind[1],\n",
    "    ),\n",
    "    fitnotype_profiles.phenotype[landscape=DD.At(1)].data,\n",
    "    dims=[1],\n",
    ")\n",
    "\n",
    "# Plot scatter for latent coordinates\n",
    "mapslices(\n",
    "    slice -> scatter!(\n",
    "        ax_latent,\n",
    "        Point2f.(eachcol(slice)),\n",
    "        markersize=5,\n",
    "        color=ColorSchemes.seaborn_colorblind[1],\n",
    "    ),\n",
    "    dd_latent.data,\n",
    "    dims=[4],\n",
    ")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this projection, we can see a qualitative agreement between the\n",
    "phenotype and latent space coordinates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear triangulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the qualitative agreement between the phenotype and latent space\n",
    "coordinates, we can now try to infer the mapping function $\\underline{g}$\n",
    "from the latent space to the phenotype space. To do this, we will train a\n",
    "simple feedforward neural network to learn the mapping function.\n",
    "\n",
    "Let's define the neural network architecture using `Flux.jl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(42)\n",
    "\n",
    "# Define neural network architecture\n",
    "nn = Flux.Chain(\n",
    "    Flux.Dense(2 => 64, Flux.identity),\n",
    "    Flux.Dense(64 => 64, Flux.leakyrelu),\n",
    "    Flux.Dense(64 => 64, Flux.leakyrelu),\n",
    "    Flux.Dense(64 => 64, Flux.leakyrelu),\n",
    "    Flux.Dense(64 => 64, Flux.leakyrelu),\n",
    "    Flux.Dense(64 => 2, Flux.identity),\n",
    ")\n",
    "\n",
    "# Move model to GPU\n",
    "nn = Flux.gpu(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's format the input and output data for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(42)\n",
    "\n",
    "# Define fraction of data to use for training\n",
    "split_frac = 0.85\n",
    "\n",
    "# Format input data\n",
    "z_in = reduce(hcat, eachslice(dd_latent.data, dims=(1, 2, 3, 5), drop=true))\n",
    "# Format output data\n",
    "x_out = reduce(\n",
    "    hcat,\n",
    "    eachslice(\n",
    "        fitnotype_profiles.phenotype[landscape=DD.At(1)].data,\n",
    "        dims=(2, 3, 4, 5),\n",
    "        drop=true\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fit model to standardize data to mean zero and standard deviation 1 on each\n",
    "# environment \n",
    "dz = StatsBase.fit(StatsBase.ZScoreTransform, z_in, dims=2)\n",
    "# Standardize the data to have mean zero and standard deviation 1\n",
    "z_in_std = StatsBase.transform(dz, z_in)\n",
    "\n",
    "# Fit model to standardize data to mean zero and standard deviation 1 on each\n",
    "# environment \n",
    "dx = StatsBase.fit(StatsBase.ZScoreTransform, x_out, dims=2)\n",
    "# Standardize the data to have mean zero and standard deviation 1\n",
    "x_out_std = StatsBase.transform(dx, x_out)\n",
    "\n",
    "# Split indexes of data into training and validation\n",
    "train_idx, val_idx = Flux.splitobs(\n",
    "    1:size(z_in, 2), at=split_frac, shuffle=true\n",
    ")\n",
    "\n",
    "# Split input and output data into training and validation\n",
    "z_in_train, z_in_val = [\n",
    "    z_in_std[:, train_idx] |> Flux.gpu, z_in_std[:, val_idx] |> Flux.gpu\n",
    "]\n",
    "x_out_train, x_out_val = [\n",
    "    x_out_std[:, train_idx] |> Flux.gpu, x_out_std[:, val_idx] |> Flux.gpu\n",
    "]\n",
    "\n",
    "# Check that input and output data have the same size\n",
    "println(\"Input and output data have the same size: $(size(z_in_train) == size(x_out_train))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train the neural network. We will use the mean squared error\n",
    "as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(42)\n",
    "\n",
    "# Define learning rate\n",
    "η = 1E-3\n",
    "# Define number of epochs\n",
    "n_epochs = 1_000\n",
    "\n",
    "# Explicit setup of optimizer\n",
    "opt_nn = Flux.Train.setup(\n",
    "    Flux.Optimisers.Adam(η),\n",
    "    nn\n",
    ")\n",
    "# Initialize loss array\n",
    "loss_train = []\n",
    "loss_val = []\n",
    "# Initialize array to store model state\n",
    "model_state = Dict()\n",
    "\n",
    "# Loop through number of epochs\n",
    "for epoch in 1:n_epochs\n",
    "    # Compute loss and gradients\n",
    "    loss, grads = Flux.withgradient(nn) do nn\n",
    "        # Forward pass on input data\n",
    "        x̂ = nn(z_in_train)\n",
    "        # Compute loss\n",
    "        Flux.Losses.mse(x̂, x_out_train)\n",
    "    end\n",
    "    # Update model parameters\n",
    "    Flux.update!(opt_nn, nn, grads[1])\n",
    "    # Store loss\n",
    "    push!(loss_train, loss)\n",
    "    # Compute validation loss\n",
    "    x̂_val = nn(z_in_val)\n",
    "    push!(loss_val, Flux.Losses.mse(x̂_val, x_out_val))\n",
    "    # Print progress\n",
    "    if epoch % 250 == 0\n",
    "        println(\"Epoch $(epoch) of $(n_epochs)\")\n",
    "        println(\"Training loss: $(loss_train[end])\")\n",
    "        println(\"Validation loss: $(loss_val[end])\")\n",
    "        model_state[epoch] = Flux.state(nn)\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training and validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig = Figure(size=(350, 300))\n",
    "\n",
    "# Add axis for training loss\n",
    "ax_train = Axis(\n",
    "    fig[1, 1],\n",
    "    title=\"Training loss\",\n",
    "    xlabel=\"epoch\",\n",
    "    ylabel=\"loss\",\n",
    "    yscale=log10,\n",
    ")\n",
    "\n",
    "# Plot training loss\n",
    "lines!(\n",
    "    ax_train,\n",
    "    loss_train,\n",
    "    color=ColorSchemes.seaborn_colorblind[1],\n",
    "    label=\"training\",\n",
    ")\n",
    "\n",
    "# Add validation loss\n",
    "lines!(\n",
    "    ax_train,\n",
    "    loss_val,\n",
    "    color=ColorSchemes.seaborn_colorblind[2],\n",
    "    label=\"validation\",\n",
    ")\n",
    "\n",
    "# Add legend\n",
    "axislegend(ax_train)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot, we can see that around 500 epochs the validation loss stops\n",
    "tracking the training loss, suggesting this as a good stopping point. So let's\n",
    "use the model state at 500 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model state\n",
    "Flux.loadmodel!(nn, model_state[500])\n",
    "# Move model to CPU\n",
    "nn = Flux.cpu(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's map the latent space coordinates to the phenotype space using the\n",
    "trained neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map latent space coordinates to phenotype space\n",
    "dd_nn = DD.DimArray(\n",
    "    mapslices(slice -> nn(slice),\n",
    "        dd_latent.data,\n",
    "        dims=[4],\n",
    "    ),\n",
    "    (\n",
    "        dd_latent.dims[1:3]...,\n",
    "        DD.dims(fitnotype_profiles.phenotype)[1],\n",
    "        dd_latent.dims[5],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Permute dimensions to have phenotype coordinates in the first dimension\n",
    "dd_nn = DD.permutedims(dd_nn, (4, 1, 2, 3, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the real and predicted phenotype coordinates next to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig = Figure(size=(600, 300))\n",
    "\n",
    "# Add axis for phenotype coordinates\n",
    "ax_pheno = Axis(\n",
    "    fig[1, 1],\n",
    "    aspect=AxisAspect(1),\n",
    "    xlabel=\"phenotype 1\",\n",
    "    ylabel=\"phenotype 2\",\n",
    ")\n",
    "\n",
    "# Add axis for predicted phenotype coordinates\n",
    "ax_pred = Axis(\n",
    "    fig[1, 2],\n",
    "    aspect=AxisAspect(1),\n",
    "    xlabel=\"predicted phenotype 1\",\n",
    "    ylabel=\"predicted phenotype 2\",\n",
    ")\n",
    "\n",
    "# Plot scatter for phenotype coordinates\n",
    "mapslices(\n",
    "    slice -> scatter!(\n",
    "        ax_pheno,\n",
    "        Point2f.(eachcol(slice)),\n",
    "        markersize=5,\n",
    "        color=ColorSchemes.seaborn_colorblind[1],\n",
    "    ),\n",
    "    fitnotype_profiles.phenotype[landscape=DD.At(1)].data,\n",
    "    dims=[1],\n",
    ")\n",
    "\n",
    "# Plot scatter for predicted phenotype coordinates\n",
    "mapslices(\n",
    "    slice -> scatter!(\n",
    "        ax_pred,\n",
    "        Point2f.(eachcol(slice)),\n",
    "        markersize=5,\n",
    "        color=ColorSchemes.seaborn_colorblind[2],\n",
    "    ),\n",
    "    dd_nn.data,\n",
    "    dims=[1],\n",
    ")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
